{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机批量梯度下降求解逻辑回归参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归的预测函数：（它表示y=1的概率）\n",
    "$$\n",
    "h_{\\theta}(x)=g\\left(\\theta^{T} x\\right)=\\frac{1}{1+e^{-\\theta^{T} x}}\n",
    "$$\n",
    "    \n",
    "在给定参数$\\theta$和自变量$x$的条件下$y$取值的条件概率是：\n",
    "$$\n",
    "P(y | x ; \\theta)=\\left(h_{\\theta}(x)\\right)^{y}\\left(1-h_{\\theta}(x)\\right)^{1-y}\n",
    "$$\n",
    "     \n",
    "写出似然函数：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &=\\prod_{i=1}^{m} P\\left(y^{(i)} | x^{(i)} ; \\theta\\right) \\\\\n",
    "&=\\prod_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)\\right)^{y^{(i)}}\\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)^{1-y^{(i)}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "     \n",
    "对数似然函数：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "l(\\theta) &=\\log L(\\theta) \\\\\n",
    "&=\\sum_{i=1}^{m}\\left(y^{(i)} \\log h_{\\theta}\\left(x^{(i)}\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "      \n",
    "目标是求得最大化似然函数的$\\theta$。定义$J(\\theta)$：\n",
    "$$\n",
    "J(\\theta)=-\\frac{1}{m} l(\\theta)\n",
    "$$\n",
    "则转化为求得使$J(\\theta)$最小的$\\theta$，可采用梯度下降进行求解。\n",
    "    \n",
    "$\\theta$的更新过程可写为（$\\alpha$为学习率）：\n",
    "$$\n",
    "\\theta_{j}:=\\theta_{j}-\\alpha \\frac{\\partial}{\\partial \\theta_{j}} J(\\theta), \\quad(j=0 \\ldots n)\n",
    "$$\n",
    "$J(\\theta)$对$\\theta$求偏导：\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_{j}} J(\\theta)\n",
    "=\\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(\\mathrm{x}^{(\\mathrm{i})}\\right)-y^{(i)}\\right) x_{j}^{(\\mathrm{i})}\n",
    "$$\n",
    "则$\\theta$的更新过程为：\n",
    "$$\n",
    "\\theta_{j}:=\\theta_{j}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(\\mathrm{x}^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}, \\quad(j=0 \\ldots n)\n",
    "$$\n",
    "    \n",
    "另外，对于学习率的调整采用指数调整：\n",
    "$$\\alpha = 0.95^{epoch\\_num} \\cdot \\alpha_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在spark中实现Logistic回归的随机梯度下降的策略是：    \n",
    "1. 给定初始的$\\theta$\n",
    "2. 随机抽取m个样本数据；\n",
    "3. map：对每一行计算梯度\n",
    "4. reduce：汇总每行梯度得到总的梯度\n",
    "5. 更新$\\theta$\n",
    "6. 重复2-5，直至$\\theta$的改变量小于某个阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.linalg import Matrix, Matrices\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "# sc = pyspark.SparkContext(\"local\", \"Simple App\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造数据\n",
    "n = 500 # 500条样本\n",
    "p = 5 # 5个变量\n",
    "theta_true = range(1,1+p) # p个参数\n",
    "np.random.seed(seed=1) # 设置随机数种子为1\n",
    "X = np.mat(np.random.randn(n,p)) # X 每个变量服从独立正态分布\n",
    "# 获取y（加上一个扰动项）\n",
    "y = np.mat(list(map(lambda x : 1 if 1/(1+math.exp(-x.dot(theta_true)+np.random.randn(1)))>0.5 else 0,X))).T\n",
    "# 训练数据\n",
    "data_xy_train = sc.parallelize(np.hstack((y,X)).tolist()[:450]) # RDD \n",
    "xy_LPtrain = data_xy_train.map(lambda line: LabeledPoint(line[0],line[1:])) # 从RDD创建LabeledPoint数据\n",
    "# 测试数据\n",
    "data_xy_test = sc.parallelize(np.hstack((y,X)).tolist()[450:]) # RDD \n",
    "xy_LPtest = data_xy_test.map(lambda line: LabeledPoint(line[0],line[1:])) # 从RDD创建LabeledPoint数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降求解参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逻辑回归的预测函数h(x,theta)\n",
    "def h(x,theta):\n",
    "    temp = math.exp(-x.dot(theta))\n",
    "    return 1 / (1 + temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一行的梯度\n",
    "# 输入为一个LabelPoint数据\n",
    "def grad_line(lineLP): \n",
    "    Xi = lineLP.features\n",
    "    yi = lineLP.label\n",
    "    # theta_value 读取广播变量的值\n",
    "    return (h(Xi,theta_bc.value) - yi)*Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次迭代更新后的theta通过广播传到各个节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc(data,alpha = 1,frac = 0.1):# 输入训练集，学习率，每次迭代所用样本比例\n",
    "    p = len(data.first().features) # 参数个数\n",
    "    theta_new = np.ones(p) # 初始化theta，全部为1\n",
    "    global theta_bc # 声明广播变量theta_bc为全局变量\n",
    "    while(1): \n",
    "        theta_j = theta_new # 更新theta\n",
    "        theta_bc = sc.broadcast(theta_j) # 将theta广播到每个节点\n",
    "        data_sub = data.sample(False,frac) # 抽取样本\n",
    "        grad_map = data_sub.map(grad_line) # 计算每行的梯度\n",
    "        grad = grad_map.sum() # 加和\n",
    "        theta_new = theta_j - alpha*grad # 新的theta_new\n",
    "        print(theta_new)\n",
    "        if norm(theta_new-theta_j)<1e-6: # 当theta在两次迭代之间的差值的二范数小于一个阈值时停止执行并返回参数\n",
    "            return theta_new\n",
    "        alpha = alpha * 0.95 # 调整学习率\n",
    "        # print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数求解：本地运行比较耗时，服务器上较快速。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.95062085  0.22275385  3.96459795  2.31184108  6.16401423]\n",
      "[ 6.0620881   2.52782468 -1.03756589  8.80180194  7.1896923 ]\n",
      "[4.26762283 2.49046076 3.97448121 6.46910487 7.90598008]\n",
      "[-0.39468331  3.01036178  4.04282461  5.46540405 10.21972445]\n",
      "[1.05612512 4.95366396 5.17188418 8.38012862 7.24833999]\n",
      "[ 2.60064386  2.17042219  5.83385397  3.81747531 11.46093891]\n",
      "[2.43151103 4.41547284 4.57673157 8.09612056 9.20319113]\n",
      "[2.91673658 2.85175445 6.86058977 6.8787412  9.61618784]\n",
      "[ 0.36619069  4.19567192  5.26500485  7.10507772 10.71888814]\n",
      "[3.29616153 4.94940749 6.34016848 7.39676559 9.41510708]\n",
      "[ 2.3813757   3.15123235  5.5589361   7.75141718 10.65855996]\n",
      "[3.14790793 3.99326719 5.00895709 8.70441915 9.78720561]\n",
      "[ 1.84490395  4.62488823  4.59290564  7.1398186  11.38449976]\n",
      "[ 0.87929177  3.54781913  6.2510076   8.23987858 10.34999172]\n",
      "[ 1.5738149   3.24719108  6.36014684  8.29164918 10.36121135]\n",
      "[ 2.01639148  3.25124764  6.43471126  8.63162754 10.00016051]\n",
      "[ 2.83433635  3.80876499  5.84934927  8.41557379 10.23493426]\n",
      "[ 2.85987274  4.52031142  5.75044257  7.63875103 10.63534156]\n",
      "[ 3.19973523  4.34378939  5.94765974  7.73178729 10.41634173]\n",
      "[ 1.43492053  3.35425633  5.51676376  8.69000376 10.64221415]\n",
      "[ 1.7500776   3.27816557  5.58555789  9.02496122 10.36906201]\n",
      "[ 1.56100024  4.27742403  6.34071797  8.15387773 10.39993316]\n",
      "[ 1.3740568   4.0673928   6.28392933  8.18536117 10.56838926]\n",
      "[ 1.27943562  4.06365437  5.7105875   8.70918088 10.48631194]\n",
      "[ 2.02992811  3.46066963  5.54944607  7.6109751  11.38490224]\n",
      "[ 0.35232226  3.38601018  5.27988966  8.61360832 11.05533037]\n",
      "[ 0.42661861  3.10801163  5.482199    8.50318009 11.16400646]\n",
      "[ 0.40505971  3.37057781  5.86051358  7.91556911 11.27994525]\n",
      "[ 0.34517203  3.67389538  6.58085529  7.65354807 10.93902392]\n",
      "[ 0.62026746  3.94772505  6.71625739  7.47376248 10.83507052]\n",
      "[ 1.62036993  4.04555093  6.1844879   7.78256295 10.7077826 ]\n",
      "[ 1.43064786  4.42605581  6.17059132  7.67468259 10.69377746]\n",
      "[ 1.53001639  4.13755728  6.36544476  7.94752814 10.40965347]\n",
      "[ 1.81487411  4.26481878  6.21751904  7.63172201 10.64315006]\n",
      "[ 1.69566011  4.36453191  6.28722677  7.77152347 10.51308517]\n",
      "[ 1.46754597  4.13449247  6.46480998  7.8258823  10.48732375]\n",
      "[ 1.43559016  4.18844253  6.30273741  7.87946334 10.48659375]\n",
      "[ 1.68951794  4.43703076  6.11656044  7.68587364 10.60184354]\n",
      "[ 1.50484118  4.09258785  6.14029687  7.78917148 10.62524946]\n",
      "[ 1.55623264  3.89551144  6.14738963  7.85884556 10.65519403]\n",
      "[ 1.47924334  3.88624424  6.20751881  7.8647691  10.65004534]\n",
      "[ 1.62849802  3.92882693  6.1489522   7.51881428 10.89841345]\n",
      "[ 1.71359471  4.17789868  6.30152944  7.55667502 10.66508254]\n",
      "[ 1.95436567  4.17088738  6.24545098  7.42402767 10.7370069 ]\n",
      "[ 1.95841964  4.3164659   6.20759471  7.53760895 10.62769761]\n",
      "[ 1.94254536  4.19101653  6.19435081  7.51089047 10.70685842]\n",
      "[ 1.87734983  4.53756858  6.03422649  7.50613292 10.67397575]\n",
      "[ 1.90460187  4.43884429  6.07772394  7.46963026 10.69916963]\n",
      "[ 1.95985722  4.40134235  6.01851471  7.62784526 10.64894115]\n",
      "[ 2.01656359  4.37018127  5.96038451  7.70722917 10.62972121]\n",
      "[ 2.16963272  4.35893916  6.15412263  7.60164515 10.56308349]\n",
      "[ 2.28249369  4.30510469  6.19591999  7.47390155 10.6398738 ]\n",
      "[ 2.26275389  4.41914472  6.24272567  7.48934196 10.56032546]\n",
      "[ 2.34454618  4.40833936  6.18128276  7.56823349 10.52567087]\n",
      "[ 2.41901087  4.3852593   6.18199053  7.57704572 10.51659918]\n",
      "[ 2.33659056  4.28079088  6.20192322  7.7501934  10.39215066]\n",
      "[ 2.30284769  4.25462786  6.13675662  7.75236209 10.44449146]\n",
      "[ 2.29479691  4.24843669  6.11188368  7.81137276 10.42914751]\n",
      "[ 2.06734957  4.22104556  6.05259471  7.81608792 10.50666968]\n",
      "[ 1.93775172  4.11245055  6.1021645   7.85591092 10.50762307]\n",
      "[ 1.95858631  4.12037359  6.10060279  7.87329755 10.49666019]\n",
      "[ 2.04239617  4.07926518  6.09796883  7.82783275 10.52512126]\n",
      "[ 2.01438547  4.12950978  6.13664074  7.8310627  10.48308976]\n",
      "[ 2.03099292  4.16954887  6.16148706  7.81554    10.46019447]\n",
      "[ 1.9987561   4.16049363  6.18946941  7.78894242 10.47682853]\n",
      "[ 2.03299929  4.19863626  6.22935648  7.76711886 10.44294371]\n",
      "[ 1.92226866  4.15593687  6.16788703  7.87288037 10.42892028]\n",
      "[ 1.89421568  4.17425916  6.16456322  7.88931414 10.42436454]\n",
      "[ 1.93445511  4.11619541  6.1807386   7.86276718 10.44743636]\n",
      "[ 1.96277575  4.1354259   6.18104378  7.80048128 10.4825145 ]\n",
      "[ 1.92054121  4.08192807  6.18710545  7.85379606 10.46684499]\n",
      "[ 1.94333757  4.04525715  6.19695717  7.82022544 10.49212292]\n",
      "[ 1.96507798  4.0882273   6.1858564   7.80028597 10.49519622]\n",
      "[ 1.97486568  4.06410804  6.18926981  7.82369963 10.48566822]\n",
      "[ 1.9604543   4.07093591  6.20038858  7.83856937 10.46373221]\n",
      "[ 1.97205809  4.13695401  6.2167079   7.83455776 10.42708668]\n",
      "[ 1.9829084   4.14134643  6.18483466  7.85886758 10.42480565]\n",
      "[ 1.98870577  4.15080397  6.18481208  7.86613854 10.41143707]\n",
      "[ 2.00254425  4.15831377  6.18443686  7.83784603 10.42474789]\n",
      "[ 1.95005468  4.14272121  6.16843172  7.81236831 10.46283899]\n",
      "[ 1.95092782  4.13804272  6.17377837  7.81105818 10.46410851]\n",
      "[ 1.97835685  4.11996411  6.16298078  7.84560589 10.44334554]\n",
      "[ 1.97709343  4.1018582   6.14893453  7.87163293 10.43992566]\n",
      "[ 1.93170722  4.08863152  6.15511629  7.87780612 10.44146354]\n",
      "[ 1.93109799  4.10856224  6.17075588  7.88518687 10.41925589]\n",
      "[ 1.94963644  4.11043377  6.18186323  7.88962293 10.40472938]\n",
      "[ 1.96530374  4.11976371  6.17442477  7.88729925 10.40477953]\n",
      "[ 1.97067428  4.09471529  6.17638375  7.89225607 10.40660689]\n",
      "[ 1.98055555  4.11265772  6.18086343  7.88542521 10.40212739]\n",
      "[ 1.99028101  4.08685599  6.17628383  7.88713695 10.40185977]\n",
      "[ 1.99362549  4.11485178  6.18337613  7.87872015 10.39087255]\n",
      "[ 2.00398254  4.10678872  6.18798747  7.88164589 10.38815718]\n",
      "[ 1.97731671  4.10970546  6.19297832  7.88894276 10.38364719]\n",
      "[ 1.98361416  4.11187967  6.19171648  7.89027048 10.38223905]\n",
      "[ 1.97211682  4.1036805   6.19038865  7.90553215 10.37663162]\n",
      "[ 1.96795671  4.1038962   6.20503221  7.90193686 10.3721519 ]\n",
      "[ 1.96849051  4.09761166  6.21603825  7.89259806 10.37461828]\n",
      "[ 1.96777597  4.10037851  6.21246273  7.89597425 10.37430845]\n",
      "[ 1.96941142  4.10331966  6.21650751  7.88909025 10.3759494 ]\n",
      "[ 1.97831499  4.09781938  6.21348467  7.8919863  10.37588067]\n",
      "[ 1.97181045  4.09593094  6.20543342  7.89777988 10.37761693]\n",
      "[ 1.98936211  4.08890636  6.20588115  7.89149735 10.38187568]\n",
      "[ 1.99438102  4.09179875  6.2099247   7.89504868 10.37553723]\n",
      "[ 1.99155182  4.09206459  6.20620716  7.89469363 10.37914417]\n",
      "[ 1.99860196  4.09287876  6.21202277  7.88820081 10.37927583]\n",
      "[ 1.99754354  4.08554599  6.2151117   7.88777124 10.37820885]\n",
      "[ 2.00122632  4.08870212  6.21049573  7.88746212 10.3784394 ]\n",
      "[ 2.00208132  4.08237974  6.21000516  7.89222819 10.37815033]\n",
      "[ 2.01605702  4.08467504  6.20850347  7.88918673 10.37693373]\n",
      "[ 2.01590548  4.08616085  6.20700663  7.89008821 10.37699526]\n",
      "[ 2.01942411  4.08351246  6.20006634  7.88627549 10.38196296]\n",
      "[ 2.02594664  4.08586611  6.19813601  7.88685952 10.3809157 ]\n",
      "[ 2.03068653  4.08177593  6.19733551  7.88631811 10.38130844]\n",
      "[ 2.03207964  4.07933583  6.19954627  7.88320683 10.38110716]\n",
      "[ 2.03482957  4.07872587  6.20222329  7.8831644  10.37868706]\n",
      "[ 2.02235295  4.07206832  6.20603929  7.88396728 10.37966992]\n",
      "[ 2.02117778  4.07448082  6.20551719  7.88542995 10.3784473 ]\n",
      "[ 2.022623    4.08424077  6.20890704  7.88633495 10.37162705]\n",
      "[ 2.02357992  4.09205353  6.21117026  7.88147531 10.3703205 ]\n",
      "[ 2.02349979  4.0908155   6.20917237  7.88389484 10.36963654]\n",
      "[ 2.02475964  4.08963322  6.20891078  7.88300653 10.36970025]\n",
      "[ 2.02062357  4.08768716  6.20922565  7.8848472  10.37008325]\n",
      "[ 2.02066033  4.08555416  6.20999801  7.88553871 10.36926116]\n",
      "[ 2.02210341  4.08414649  6.20781428  7.88419063 10.37058491]\n",
      "[ 2.02301812  4.08300935  6.2091615   7.88280098 10.37130096]\n",
      "[ 2.02381407  4.08463608  6.21284712  7.88399979 10.36764019]\n",
      "[ 2.02622176  4.08794762  6.21209616  7.8799129  10.36903535]\n",
      "[ 2.02606503  4.08557785  6.2132299   7.87924836 10.36990333]\n",
      "[ 2.02755699  4.08505006  6.21288255  7.87974653 10.36979094]\n",
      "[ 2.02590775  4.08483124  6.21233206  7.88023    10.37008301]\n",
      "[ 2.02475993  4.08617781  6.21279626  7.88043314 10.36912551]\n",
      "[ 2.0264298   4.08578312  6.2132996   7.88026047 10.36866563]\n",
      "[ 2.0255962   4.0838472   6.21303085  7.88056244 10.36962477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.02877874  4.08576465  6.21617707  7.87932832 10.36707442]\n",
      "[ 2.02988848  4.08465935  6.21738369  7.87821033 10.36679507]\n",
      "[ 2.02911059  4.08381853  6.2171012   7.87976412 10.36635404]\n",
      "[ 2.02929691  4.08251737  6.21863691  7.87872813 10.36665808]\n",
      "[ 2.02595392  4.08167161  6.21821938  7.88057804 10.36658457]\n",
      "[ 2.02315673  4.08231023  6.21799518  7.88227302 10.36583113]\n",
      "[ 2.02387998  4.08196556  6.21712305  7.88339621 10.36558809]\n",
      "[ 2.02517242  4.0821851   6.21651552  7.88226563 10.36625716]\n",
      "[ 2.02403778  4.08289881  6.21525939  7.88422215 10.36542306]\n",
      "[ 2.02436405  4.08385435  6.21665845  7.88285432 10.36488848]\n",
      "[ 2.02456859  4.08459966  6.21594019  7.88236467 10.36534031]\n",
      "[ 2.02406543  4.08455667  6.21585672  7.88260822 10.36531969]\n",
      "[ 2.02332283  4.08473767  6.21643067  7.88213219 10.36550912]\n",
      "[ 2.02297957  4.0853484   6.21556445  7.88155925 10.36624071]\n",
      "[ 2.02355077  4.08516358  6.21542283  7.88086014 10.36680438]\n",
      "[ 2.02412754  4.08437364  6.21470651  7.88013811 10.36760946]\n",
      "[ 2.02501468  4.0826799   6.21381391  7.88091091 10.36768889]\n",
      "[ 2.0235639   4.08233896  6.21340341  7.88159879 10.36786598]\n",
      "[ 2.02387984  4.08328084  6.21333894  7.88217131 10.36701858]\n",
      "[ 2.02461671  4.08413086  6.21343735  7.88235093 10.36628338]\n",
      "[ 2.02496627  4.08433208  6.21401232  7.88136474 10.36648676]\n",
      "[ 2.02462539  4.08401876  6.21427302  7.88101226 10.36671064]\n",
      "[ 2.02462758  4.08389257  6.21447376  7.88148074 10.36634405]\n",
      "[ 2.02440976  4.08352573  6.21436399  7.88127051 10.36678706]\n",
      "[ 2.02347138  4.08363573  6.21415526  7.88179133 10.36659876]\n",
      "[ 2.0232025   4.08384932  6.21421573  7.8820895  10.36635594]\n",
      "[ 2.02317633  4.08329677  6.21441339  7.88249914 10.36602748]\n",
      "[ 2.0233061   4.08320908  6.21501877  7.88227797 10.36587082]\n",
      "[ 2.02370807  4.08330246  6.21495471  7.88238806 10.36573073]\n",
      "[ 2.02366142  4.08298686  6.21479166  7.88259413 10.36580636]\n",
      "[ 2.02380552  4.0827847   6.21489019  7.88263989 10.36568209]\n",
      "[ 2.02377212  4.08279473  6.21487207  7.88263093 10.36573425]\n",
      "[ 2.02350846  4.08283069  6.21462819  7.88271328 10.36579247]\n",
      "[ 2.02378277  4.08314121  6.21476233  7.88259239 10.36565328]\n",
      "[ 2.02388344  4.08302247  6.21456214  7.8825515  10.3658001 ]\n",
      "[ 2.02404231  4.08300223  6.21449535  7.88270665 10.36570646]\n",
      "[ 2.02432099  4.08334637  6.21419595  7.88267297 10.36568892]\n",
      "[ 2.0243536   4.08323402  6.21406416  7.88280993 10.36569464]\n",
      "[ 2.02363989  4.08314703  6.21384241  7.88303867 10.36577307]\n",
      "[ 2.02367269  4.0829956   6.21401068  7.8831504  10.36565882]\n",
      "[ 2.02368719  4.08272128  6.21405558  7.88293162 10.36587059]\n",
      "[ 2.02373269  4.08253223  6.21422709  7.88306603 10.36569522]\n",
      "[ 2.02380862  4.08243912  6.21406071  7.88317824 10.36573704]\n",
      "[ 2.0239298   4.08246782  6.21410579  7.88311493 10.36574667]\n",
      "[ 2.02398823  4.08222518  6.21409397  7.88307044 10.36585854]\n",
      "[ 2.02407629  4.0820557   6.21431759  7.88287196 10.36592622]\n",
      "[ 2.02374206  4.0818626   6.21443392  7.88300573 10.36585053]\n",
      "[ 2.02369412  4.08193709  6.21437327  7.88322434 10.36569434]\n",
      "[ 2.02353982  4.0816575   6.21438544  7.88340728 10.36565548]\n",
      "[ 2.02362546  4.08153428  6.21438123  7.88340574 10.36570058]\n",
      "[ 2.02357005  4.08142912  6.21458606  7.88334591 10.36567754]\n",
      "[ 2.02357413  4.08143135  6.21461402  7.883352   10.36566418]\n",
      "[ 2.02340078  4.08143697  6.21456217  7.88350381 10.36557185]\n",
      "[ 2.0234146   4.08129956  6.21456702  7.88361632 10.36554561]\n",
      "[ 2.02356567  4.08122322  6.21450031  7.88360062 10.3655663 ]\n",
      "[ 2.02353986  4.08117376  6.21451033  7.88362963 10.36557079]\n",
      "[ 2.02348443  4.08120214  6.21443366  7.88373005 10.36554843]\n",
      "[ 2.02354456  4.08123767  6.21445566  7.88371613 10.36551381]\n",
      "[ 2.02350472  4.08126286  6.21462965  7.88370103 10.36540942]\n",
      "[ 2.02351582  4.08130657  6.21465963  7.88367226 10.3653798 ]\n",
      "[ 2.02347827  4.0812839   6.21459811  7.88373017 10.36539053]\n",
      "[ 2.02351783  4.08129342  6.21460397  7.88372847 10.3653819 ]\n",
      "[ 2.0236389   4.08131035  6.21459048  7.88362823 10.36542471]\n",
      "[ 2.02367197  4.08140158  6.21458612  7.88356573 10.36543197]\n",
      "[ 2.02371334  4.08141685  6.21454683  7.88354339 10.36544769]\n",
      "[ 2.02369328  4.08133271  6.21450405  7.883542   10.36550165]\n",
      "[ 2.02375159  4.08137468  6.21450336  7.8835151  10.36548834]\n",
      "[ 2.02382943  4.0813946   6.21447552  7.88349738 10.36547537]\n",
      "[ 2.02383829  4.0813817   6.21448391  7.8834569  10.36550631]\n",
      "[ 2.02386588  4.08137631  6.21446001  7.8834131  10.36553568]\n",
      "[ 2.02392165  4.08133145  6.21442448  7.88341389 10.36555272]\n",
      "[ 2.02390902  4.08130284  6.21439876  7.8834239  10.36557173]\n",
      "[ 2.02389916  4.08131756  6.21439755  7.88336568 10.36560405]\n",
      "[ 2.02388685  4.08133725  6.21439619  7.88338399 10.36558882]\n",
      "[ 2.02389584  4.08134193  6.2143796   7.88340296 10.36558647]\n",
      "[ 2.02387426  4.08136222  6.21440055  7.88338918 10.36557674]\n",
      "[ 2.02384925  4.08142095  6.21436432  7.88339993 10.36556924]\n",
      "[ 2.02385428  4.08146107  6.21435073  7.88338153 10.36557366]\n",
      "[ 2.02383518  4.08147401  6.21437339  7.88337621 10.36556201]\n",
      "[ 2.02382441  4.08145759  6.21436845  7.88338003 10.36557179]\n",
      "[ 2.02378982  4.08145412  6.21440516  7.88338546 10.36555296]\n",
      "[ 2.02378969  4.08143756  6.21439614  7.8833718  10.36557334]\n",
      "[ 2.02379983  4.08144629  6.21438113  7.88335676 10.36558902]\n",
      "[ 2.02381785  4.0814629   6.21438034  7.88334577 10.3655824 ]\n",
      "[ 2.02380361  4.08148144  6.21438268  7.8833503  10.36557216]\n",
      "[ 2.02381582  4.08148807  6.21438627  7.88334854 10.36556719]\n",
      "[ 2.02382102  4.08149647  6.21440248  7.88335194 10.36555143]\n",
      "[ 2.02382807  4.08147204  6.21440735  7.88334376 10.36555933]\n",
      "[ 2.02382256  4.08149311  6.21438931  7.88333683 10.36556849]\n",
      "[ 2.02383847  4.08152577  6.21438299  7.88333904 10.3655515 ]\n",
      "[ 2.02382589  4.08151479  6.21437113  7.88337165 10.36553905]\n",
      "[ 2.02384661  4.08151935  6.214362    7.88337072 10.36553894]\n",
      "[ 2.02382893  4.0815111   6.21438086  7.88338188 10.36551974]\n",
      "[ 2.02380695  4.08150556  6.21437995  7.88339408 10.36551754]\n",
      "[ 2.02379773  4.08151752  6.21438876  7.88339272 10.36551   ]\n",
      "[ 2.02381532  4.08154066  6.21438666  7.88339672 10.36549467]\n",
      "[ 2.02380165  4.08151988  6.2143836   7.88341377 10.36549365]\n",
      "[ 2.02380983  4.08152111  6.21438114  7.88341517 10.36549265]\n",
      "[ 2.02380972  4.08151646  6.2143831   7.88340693 10.36549592]\n",
      "[ 2.02380235  4.08151486  6.21438178  7.88341873 10.36549015]\n",
      "[ 2.02379636  4.08152986  6.21437679  7.88341425 10.3654905 ]\n",
      "[ 2.02380592  4.08153896  6.21437918  7.88340846 10.36548827]\n",
      "[ 2.02380624  4.08153049  6.21436934  7.88342075 10.36548614]\n",
      "[ 2.02379684  4.08152715  6.21436537  7.88342236 10.36549012]\n",
      "[ 2.02380508  4.0815229   6.21436621  7.88341369 10.36549631]\n",
      "[ 2.02380757  4.08151559  6.21436564  7.88341261 10.36549869]\n",
      "[ 2.02381088  4.08151658  6.21436267  7.88341847 10.36549309]\n",
      "[ 2.02381454  4.08151815  6.21436081  7.883423   10.3654901 ]\n",
      "[ 2.02381597  4.08151893  6.21436077  7.88342297 10.36549   ]\n",
      "[ 2.02381652  4.08151797  6.21436053  7.88342358 10.36549037]\n",
      "[ 2.02381785  4.0815108   6.2143606   7.88342992 10.3654859 ]\n",
      "[ 2.02381501  4.08151588  6.21436474  7.88342156 10.36548663]\n",
      "[ 2.02381651  4.08151597  6.21436618  7.88342373 10.36548233]\n",
      "[ 2.02381299  4.0815127   6.21436358  7.88342494 10.36548551]\n",
      "[ 2.02381089  4.08151388  6.2143633   7.88342892 10.36548319]\n",
      "[ 2.023813    4.08151095  6.21436163  7.88343149 10.36548314]\n",
      "[ 2.02381465  4.08151192  6.21436484  7.88342873 10.36548264]\n",
      "[ 2.02381594  4.08151235  6.21436985  7.88342392 10.36548319]\n",
      "[ 2.02381921  4.0815107   6.21436848  7.88342411 10.36548433]\n",
      "[ 2.02382044  4.08150981  6.2143681   7.88342471 10.36548468]\n",
      "[ 2.02382015  4.08151009  6.21437032  7.88342494 10.36548337]\n",
      "[ 2.02381588  4.08151409  6.21436763  7.88342616 10.36548313]\n",
      "[ 2.02381948  4.08151447  6.21437354  7.88342374 10.36548084]\n",
      "[ 2.02382091  4.08151427  6.21437374  7.88342363 10.3654808 ]\n",
      "[ 2.0238217   4.08151489  6.21436914  7.88342581 10.36548122]\n",
      "[ 2.02382063  4.08151374  6.21436938  7.88342531 10.36548218]\n",
      "[ 2.02382126  4.08151256  6.21436948  7.88342281 10.36548466]\n",
      "[ 2.02382131  4.0815129   6.21437342  7.8834215  10.36548322]\n",
      "[ 2.02382353  4.08151031  6.21437629  7.88342091 10.36548202]\n",
      "[ 2.02382081  4.08151016  6.21437604  7.88342183 10.36548186]\n",
      "[ 2.02382414  4.0815103   6.21437449  7.88342444 10.36548022]\n",
      "[ 2.02382286  4.0815115   6.21437749  7.8834227  10.36547955]\n",
      "[ 2.02382306  4.08151177  6.21437829  7.88342339 10.36547866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.02382199  4.08151149  6.21438116  7.88342369 10.3654773 ]\n",
      "[ 2.02382197  4.08151123  6.21438092  7.8834242  10.36547745]\n"
     ]
    }
   ],
   "source": [
    "# 参数求解\n",
    "theta = grad_desc(xy_LPtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.02382197,  4.08151123,  6.21438092,  7.8834242 , 10.36547745])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测效果评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个样本的预测结果\n",
    "def predict_line(lineLP):\n",
    "    Xi = lineLP.features\n",
    "    yi = lineLP.label\n",
    "    # theta_bc.value 读取广播变量的值\n",
    "    Pi = h(Xi,theta_bc.value) # 计算S函数值\n",
    "    yi_hat = 1 if Pi>0.5 else 0 \n",
    "    if yi==1: # [TP,FP,FN,TN]\n",
    "        if yi_hat ==1: return np.array([1,0,0,0])\n",
    "        else: return np.array([0,0,1,0])\n",
    "    elif yi_hat ==1: return np.array([0,1,0,0])\n",
    "    return np.array([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_performance(data_new,theta):\n",
    "    global theta_bc # 声明广播变量theta为全局变量\n",
    "    theta_bc = sc.broadcast(theta) # 广播theta\n",
    "    pred_map = data_new.map(predict_line) # 获取每一条观测的预测情况\n",
    "    pred_reduce = pred_map.reduce(add) # 整合所有预测情况\n",
    "    accuracy = (pred_reduce[0]+pred_reduce[3])/sum(pred_reduce) # 准确率\n",
    "    precision = pred_reduce[0]/(pred_reduce[0]+pred_reduce[1]) # 查准率\n",
    "    recall = pred_reduce[0]/(pred_reduce[0]+pred_reduce[2]) # 召回率\n",
    "    return [accuracy,precision,recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction performace in training set: \n",
      "accuracy:  0.94 \n",
      "precision:  0.94 \n",
      "recall:  0.95\n",
      "Prediction performace in test set: \n",
      "accuracy:  0.98 \n",
      "precision:  1.0 \n",
      "recall:  0.95\n"
     ]
    }
   ],
   "source": [
    "# 训练样本上的准确率\n",
    "train_pfm = predict_performance(xy_LPtrain,theta)\n",
    "print('Prediction performace in training set: \\naccuracy: ',\n",
    "     round(train_pfm[0],2),'\\nprecision: ',round(train_pfm[1],2),\n",
    "     '\\nrecall: ',round(train_pfm[2],2))\n",
    "\n",
    "# 测试样本上的准确率\n",
    "test_pfm = predict_performance(xy_LPtest,theta)\n",
    "print('Prediction performace in test set: \\naccuracy: ',\n",
    "     round(test_pfm[0],2),'\\nprecision: ',round(test_pfm[1],2),\n",
    "     '\\nrecall: ',round(test_pfm[2],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比mllib中的逻辑回归模型估计函数LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.6814, 3.3606, 5.1239, 6.5283, 8.5064])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(xy_LPtrain)\n",
    "mllib_theta = model.weights\n",
    "mllib_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction performace in training set: \n",
      "accuracy:  0.94 \n",
      "precision:  0.94 \n",
      "recall:  0.95\n",
      "Prediction performace in test set: \n",
      "accuracy:  0.94 \n",
      "precision:  0.94 \n",
      "recall:  0.95\n"
     ]
    }
   ],
   "source": [
    "# 训练样本上的准确率\n",
    "mllib_train_pfm = predict_performance(xy_LPtrain,mllib_theta)\n",
    "print('Prediction performace in training set: \\naccuracy: ',\n",
    "     round(mllib_train_pfm[0],2),'\\nprecision: ',round(mllib_train_pfm[1],2),\n",
    "     '\\nrecall: ',round(mllib_train_pfm[2],2))\n",
    "\n",
    "# 测试样本上的准确率\n",
    "mllib_test_pfm = predict_performance(xy_LPtest,mllib_theta)\n",
    "print('Prediction performace in test set: \\naccuracy: ',\n",
    "     round(mllib_train_pfm[0],2),'\\nprecision: ',round(mllib_train_pfm[1],2),\n",
    "     '\\nrecall: ',round(mllib_train_pfm[2],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自行实现的梯度下降求解参数的逻辑回归模型在测试集上的表现优于millib库中自带的LogisticRegressionWithLBFGS函数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
